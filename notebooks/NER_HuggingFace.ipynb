{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrJmcBvfsGYyHhS9YgcQiq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1740c911cbb84737960be3da019a81dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94e63196248c488dbc0cf69dca73840c",
              "IPY_MODEL_cb8e1687f5834f0b95c3ac53c3d3d5a0",
              "IPY_MODEL_eda2f714d9794a978b71820b7425ed88"
            ],
            "layout": "IPY_MODEL_fb2c964e42ae4828bdba0b3f2ee7a7f4"
          }
        },
        "94e63196248c488dbc0cf69dca73840c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b483f0868b4c9a91001829f6969d82",
            "placeholder": "​",
            "style": "IPY_MODEL_04f353ecc12b429082ad49ba35afb8e5",
            "value": "100%"
          }
        },
        "cb8e1687f5834f0b95c3ac53c3d3d5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af9441ed54af473d8e67be8d5b5d6676",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b04cf9950774a618a4e3909fc0a0b19",
            "value": 3
          }
        },
        "eda2f714d9794a978b71820b7425ed88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6980ccde2e9d4ebcb5d83c03b9ce5d95",
            "placeholder": "​",
            "style": "IPY_MODEL_d3eb329b382941d0a14d7e0c0902e20d",
            "value": " 3/3 [00:00&lt;00:00, 97.40it/s]"
          }
        },
        "fb2c964e42ae4828bdba0b3f2ee7a7f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b483f0868b4c9a91001829f6969d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04f353ecc12b429082ad49ba35afb8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af9441ed54af473d8e67be8d5b5d6676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b04cf9950774a618a4e3909fc0a0b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6980ccde2e9d4ebcb5d83c03b9ce5d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3eb329b382941d0a14d7e0c0902e20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurziegler/transformers-for-NLP/blob/main/notebooks/NER_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXynW2miSkz8",
        "outputId": "e2d45238-338f-4f05-9f15-4f5505a5fb8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.8/dist-packages (0.15.0)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.8/dist-packages (7.352.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.13.0+cu116)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets accelerate nvidia-ml-py3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "1YR_Ro7FSzse"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "1740c911cbb84737960be3da019a81dd",
            "94e63196248c488dbc0cf69dca73840c",
            "cb8e1687f5834f0b95c3ac53c3d3d5a0",
            "eda2f714d9794a978b71820b7425ed88",
            "fb2c964e42ae4828bdba0b3f2ee7a7f4",
            "00b483f0868b4c9a91001829f6969d82",
            "04f353ecc12b429082ad49ba35afb8e5",
            "af9441ed54af473d8e67be8d5b5d6676",
            "5b04cf9950774a618a4e3909fc0a0b19",
            "6980ccde2e9d4ebcb5d83c03b9ce5d95",
            "d3eb329b382941d0a14d7e0c0902e20d"
          ]
        },
        "id": "M7RcEyGxS2FC",
        "outputId": "4eb5c558-a5a6-4093-fb75-fcd3b7a198b3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset conll2003 (/root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1740c911cbb84737960be3da019a81dd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn1SqfEZS54q",
        "outputId": "d715e58e-ff80-4b1b-e91b-b5ac037ae9e8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can see that each item in the dataset is a sentence but its token and targets columns are lists divided by the words of the sentence\n",
        "data['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYm13YrJS7iu",
        "outputId": "c20cde1a-9741-4a2d-cb3a-cf7aafffa803"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'].features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfLNvKijS-Cr",
        "outputId": "20b6e768-e47c-4bf4-c195-6cf0ba7ec560"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': Value(dtype='string', id=None),\n",
              " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'pos_tags': Sequence(feature=ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None),\n",
              " 'chunk_tags': Sequence(feature=ClassLabel(names=['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP'], id=None), length=-1, id=None),\n",
              " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'].features['ner_tags']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi1fBHEiTUHD",
        "outputId": "148eb59b-b725-47f0-dfd4-7f91cae1b437"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'].features['ner_tags'].feature.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jib_jnTqTgjS",
        "outputId": "67102d2b-5c7d-441c-f0ec-eb49eb323c00"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We save the feature names to use later\n",
        "label_names = data['train'].features['ner_tags'].feature.names"
      ],
      "metadata": {
        "id": "jeHP1BJiTjAb"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "SVcAh3lITvAR"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = 'distilbert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4Q0-qGsTz9N",
        "outputId": "e001e255-c111-4387-d6fb-de641a2a5d63"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-cased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-cased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "t = tokenizer(data['train'][idx]['tokens'], is_split_into_words=True)\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok_lrltHT57t",
        "outputId": "836d23b4-3847-4e26-f54d-5d28d8e3d4e8"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The tokenizer return looks like a dictionary but it is actually an object called BatchEncoding\n",
        "type(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp6vgCEXUHpw",
        "outputId": "8f01d28b-94b1-4003-812b-94ec6c93175a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The object has a tokens method that returns the original tokens before transforming them into integers\n",
        "t.tokens()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHOP9NAlUdf6",
        "outputId": "1e36ed06-51cc-4a64-f273-3c99ec9cd9b5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'EU',\n",
              " 'rejects',\n",
              " 'German',\n",
              " 'call',\n",
              " 'to',\n",
              " 'boycott',\n",
              " 'British',\n",
              " 'la',\n",
              " '##mb',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.word_ids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wLJzxQDzO6C",
        "outputId": "376dbf2d-1308-4f6d-beeb-788739cdf76c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define relationship between B and I tags\n",
        "#['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
        "begin2inside = {\n",
        "    1:2,\n",
        "    3:4,\n",
        "    5:6,\n",
        "    7:8\n",
        "}"
      ],
      "metadata": {
        "id": "HwJwFPv-zO8Y"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_targets(labels, word_ids):\n",
        "    aligned_labels = []\n",
        "    previous_word = None\n",
        "\n",
        "    for word in word_ids:\n",
        "        if word is None:\n",
        "            # Tokens like [CLS] and [SEP]\n",
        "            label = -100 #This value is used by Hugging Face to ignore the tokens during training\n",
        "        elif word != previous_word:\n",
        "            # New word in the list\n",
        "            label = labels[word]\n",
        "        else:\n",
        "            #Repeated word (Would be the next sub-word)\n",
        "            if labels[word] in begin2inside:\n",
        "                #Change B-<tag> to I-<tag>\n",
        "                label = begin2inside[labels[word]]\n",
        "            else:\n",
        "                # Sub-word of a word classified as \"O\" gets the same label \"O\"\n",
        "                label = labels[word]\n",
        "\n",
        "        aligned_labels.append(label)\n",
        "        previous_word = word #update last word\n",
        " \n",
        "    return aligned_labels"
      ],
      "metadata": {
        "id": "I2Vjs6iaXOrH"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Label-Token Alignment Test\n",
        "idx = 21\n",
        "test_data = tokenizer(data['train'][idx]['tokens'], is_split_into_words=True)\n",
        "print(\"Tokenized Data:\", test_data)\n",
        "print(\"Word Tokens:\", data['train'][idx]['tokens'])\n",
        "test_labels = data['train'][idx]['ner_tags']\n",
        "print(\"Word Labels:\", test_labels)\n",
        "print(\"Word IDs:\", test_data.word_ids())\n",
        "aligned_targets = align_targets(test_labels, test_data.word_ids())\n",
        "print(\"Sub-Word Labels:\", aligned_targets)\n",
        "print(\"Sub-Word Tokens:\", test_data.tokens())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qrz40NWcKCs",
        "outputId": "6d7ecacd-c8dd-497f-f160-bd88c70cf403"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Data: {'input_ids': [101, 149, 11414, 2137, 11414, 1820, 118, 4775, 118, 1659, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "Word Tokens: ['LONDON', '1996-08-22']\n",
            "Word Labels: [5, 0]\n",
            "Word IDs: [None, 0, 0, 0, 0, 1, 1, 1, 1, 1, None]\n",
            "Sub-Word Labels: [-100, 5, 6, 6, 6, 0, 0, 0, 0, 0, -100]\n",
            "Sub-Word Tokens: ['[CLS]', 'L', '##ON', '##D', '##ON', '1996', '-', '08', '-', '22', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aligned_labels = [label_names[t] if t>=0 else None for t in aligned_targets]\n",
        "for x, y in zip(test_data.tokens(), aligned_labels):\n",
        "    print(f\"{x}\\t{y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyovRuga2XYw",
        "outputId": "6c6b8258-a03d-4b66-a1d2-8ed327262553"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]\tNone\n",
            "L\tB-LOC\n",
            "##ON\tI-LOC\n",
            "##D\tI-LOC\n",
            "##ON\tI-LOC\n",
            "1996\tO\n",
            "-\tO\n",
            "08\tO\n",
            "-\tO\n",
            "22\tO\n",
            "[SEP]\tNone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to tokenize both inputs and targets\n",
        "def tokenize_fn(batch):\n",
        "    # Tokenize the input sequence first\n",
        "    tokenized_inputs = tokenizer(batch['tokens'], truncation=True, is_split_into_words=True)\n",
        "    labels_batch = batch['ner_tags'] # The original targets word-by-word\n",
        "    aligned_labels_batch = [] # The aligned targets sub-word by sub-word\n",
        "    # Loop through each label sequence in the batch\n",
        "    for i, labels in enumerate(labels_batch):\n",
        "        word_ids = tokenized_inputs.word_ids(i) # Get word IDs for the sequence\n",
        "        aligned_labels_batch.append(align_targets(labels, word_ids)) # Align sequence labels\n",
        "    \n",
        "    # Save final aligned labels in a column called 'labels' which is the required name for the hugging face models\n",
        "    tokenized_inputs['labels'] = aligned_labels_batch\n",
        "    \n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "VW8BqJqje7sg"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"train\"].column_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teusFKI789Jy",
        "outputId": "131c6978-49a1-4049-96be-c8c853ad2ef3"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags']"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = data.map(\n",
        "\ttokenize_fn,\n",
        "\tbatched=True,\n",
        "\tremove_columns=data[\"train\"].column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj8YttfRyUsA",
        "outputId": "ec2dded9-b0af-49c9-89b4-14e394c58f14"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-717390b78533cb11.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-ab2412e71833caf1.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-1c25f4869dd2d594.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpu4Xfsr9L1M",
        "outputId": "3b52c15c-4e69-4edd-b13d-a42d0c1411cf"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification"
      ],
      "metadata": {
        "id": "oe6LZ3UF9f7n"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "data_collator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u45_xWCjTP0b",
        "outputId": "86648010-f41a-45e0-f178-c82bc5c97d63"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataCollatorForTokenClassification(tokenizer=PreTrainedTokenizerFast(name_or_path='distilbert-base-cased', vocab_size=28996, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='pt')"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the data collator\n",
        "# First we need to define a list of samples from our dataset\n",
        "collator_testset = [tokenized_datasets[\"train\"][i] for i in range(2)]"
      ],
      "metadata": {
        "id": "GWlTxTDeTYRX"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collator_testset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQip22QFTsy8",
        "outputId": "61aba59e-07d7-4a99-e523-c5e6f7fd3620"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input_ids': [101,\n",
              "   7270,\n",
              "   22961,\n",
              "   1528,\n",
              "   1840,\n",
              "   1106,\n",
              "   21423,\n",
              "   1418,\n",
              "   2495,\n",
              "   12913,\n",
              "   119,\n",
              "   102],\n",
              "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "  'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]},\n",
              " {'input_ids': [101, 1943, 14428, 102],\n",
              "  'attention_mask': [1, 1, 1, 1],\n",
              "  'labels': [-100, 1, 2, -100]}]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_collator(collator_testset)\n",
        "batch[\"labels\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRsT-lYdT7Ns",
        "outputId": "07d81155-104e-40a6-b818-47d40d3ca071"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
              "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "aqUZrUZbUUnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882fc690-fd49-43e5-cc2d-577ad0516df0"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.8/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric"
      ],
      "metadata": {
        "id": "tg3WBnz3WxTS"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"seqeval\")"
      ],
      "metadata": {
        "id": "TaMuNypqWzf9"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to use the compute metrics for a sequence\n",
        "# It will give an error as the method work only with sequences of sequences\n",
        "metric.compute(predictions=[0, 0, 0], references=[0, 0, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "jLDYzTBJW58G",
        "outputId": "d0ac7a0e-213a-486b-c22c-c8f1d7b78b46"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-94636a875620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Try to use the compute metrics for a sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# It will give an error as the method work only with sequences of sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/metric.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/metric.py\u001b[0m in \u001b[0;36madd_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"predictions\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"references\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mintput_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintput_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mintput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mencode_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast_to_python_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1818\u001b[0;31m             \u001b[0mencoded_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1819\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoded_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast_to_python_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1818\u001b[0;31m             \u001b[0mencoded_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1819\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoded_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got a string but expected a list instead: '{obj}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfirst_elmt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0m_check_non_null_non_empty_recursive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_elmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the compute metrics again as a list of lists\n",
        "# There will be warnings that the labels passed are integers instead of strings\n",
        "metric.compute(\n",
        "    predictions=[[0, 0, 0], [1, 0, 1]], \n",
        "    references=[[0, 0, 1], [1, 0, 1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTPoWLFLXFJc",
        "outputId": "6def40f1-8675-4ef2-e86f-88de26bcb162"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overall_precision': 0.0,\n",
              " 'overall_recall': 0.0,\n",
              " 'overall_f1': 0.0,\n",
              " 'overall_accuracy': 0.8333333333333334}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the compute metrics again as a list of lists of a character\n",
        "# There will be warnings that the labels passed are not NE tags\n",
        "metric.compute(\n",
        "    predictions=[['A', 'A', 'A'], ['A', 'B', 'C']], \n",
        "    references=[['A', 'C', 'A'], ['B', 'B', 'C']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiM5SdHZXYSQ",
        "outputId": "06134f4d-7526-4f65-8b86-7a095669b294"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: A seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: C seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
              " 'overall_precision': 0.0,\n",
              " 'overall_recall': 0.0,\n",
              " 'overall_f1': 0.0,\n",
              " 'overall_accuracy': 0.6666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the compute metrics again as a list of lists of valid NE IOB tags\n",
        "metric.compute(\n",
        "    predictions=[['O', 'O', 'I-ORG'], ['B-MISC', 'O', 'B-PER']], \n",
        "    references=[['O', 'B-LOC', 'B-ORG'], ['B-MISC', 'I-MISC', 'B-PER']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "565Dr3aCYKY6",
        "outputId": "1e5992bb-79eb-4df6-dc9b-f7d0ae82e6e5"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
              " 'MISC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
              " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
              " 'PER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
              " 'overall_precision': 0.6666666666666666,\n",
              " 'overall_recall': 0.5,\n",
              " 'overall_f1': 0.5714285714285715,\n",
              " 'overall_accuracy': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "G8ch8DdHagQj"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(logits_and_labels):\n",
        "    logits, labels = logits_and_labels\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # remove -100, convert the label ids to label names\n",
        "    str_labels = [[label_names[t] for t in label if t != -100] for label in labels]\n",
        "\n",
        "    # do the same for predictions whenever true label is -100\n",
        "    str_preds = [[label_names[p] for p, t in zip(pred, targ) if t != -100] for pred, targ in zip(preds, labels)]\n",
        "\n",
        "    the_metrics = metric.compute(predictions=str_preds, references=str_labels)\n",
        "    return {\n",
        "        'precision': the_metrics['overall_precision'],\n",
        "        'recall': the_metrics['overall_recall'],\n",
        "        'f1': the_metrics['overall_f1'],\n",
        "        'accuracy': the_metrics['overall_accuracy']\n",
        "        }"
      ],
      "metadata": {
        "id": "n2fb2q0rbpVn"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {k: v for k, v in enumerate(label_names)} #Get label IDs\n",
        "label2id = {v: k for k, v in id2label.items()} #Get label names from IDs\n",
        "id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mro2qjLYb8Wm",
        "outputId": "9c883dc7-4b3a-44ef-ee32-61613c33b3bd"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'O',\n",
              " 1: 'B-PER',\n",
              " 2: 'I-PER',\n",
              " 3: 'B-ORG',\n",
              " 4: 'I-ORG',\n",
              " 5: 'B-LOC',\n",
              " 6: 'I-LOC',\n",
              " 7: 'B-MISC',\n",
              " 8: 'I-MISC'}"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification"
      ],
      "metadata": {
        "id": "VY0tn7yUcx1b"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ],
      "metadata": {
        "id": "wb730v5_eT8_",
        "outputId": "aeb8561f-e5fa-4b9e-b4b1-bee1e0a199db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-cased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"B-PER\",\n",
            "    \"2\": \"I-PER\",\n",
            "    \"3\": \"B-ORG\",\n",
            "    \"4\": \"I-ORG\",\n",
            "    \"5\": \"B-LOC\",\n",
            "    \"6\": \"I-LOC\",\n",
            "    \"7\": \"B-MISC\",\n",
            "    \"8\": \"I-MISC\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"B-LOC\": 5,\n",
            "    \"B-MISC\": 7,\n",
            "    \"B-ORG\": 3,\n",
            "    \"B-PER\": 1,\n",
            "    \"I-LOC\": 6,\n",
            "    \"I-MISC\": 8,\n",
            "    \"I-ORG\": 4,\n",
            "    \"I-PER\": 2,\n",
            "    \"O\": 0\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/pytorch_model.bin\n",
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    \"distilbert-finetuned-ner\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "JKPfDh9PeeUC",
        "outputId": "4c7166f3-aab8-49ee-ac02-450192f9cc7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "DPO6muL4fQoA"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pynvml import *\n",
        "\n",
        "\n",
        "def print_gpu_utilization():\n",
        "    nvmlInit()\n",
        "    handle = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
        "\n",
        "\n",
        "def print_summary(result):\n",
        "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print_gpu_utilization()"
      ],
      "metadata": {
        "id": "KFU6N80kVJsY"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainer.args.device)\n",
        "print_gpu_utilization()\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "w88tXwr4n6SB",
        "outputId": "f070cfe1-c834-4bba-d266-e9ef741b887b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "GPU memory occupied: 2686 MB.\n",
            "Sun Jan  1 20:40:25 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    28W /  70W |   2686MiB / 15109MiB |     11%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = trainer.train()\n",
        "print_summary(result)"
      ],
      "metadata": {
        "id": "Ju3c_r7On3YD",
        "outputId": "be5c9d62-1d15-4292-ef78-012a4843ed87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 14041\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5268\n",
            "  Number of trainable parameters = 65197833\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5268' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5268/5268 05:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.103500</td>\n",
              "      <td>0.084191</td>\n",
              "      <td>0.895136</td>\n",
              "      <td>0.913665</td>\n",
              "      <td>0.904306</td>\n",
              "      <td>0.975717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.045000</td>\n",
              "      <td>0.077397</td>\n",
              "      <td>0.907968</td>\n",
              "      <td>0.928139</td>\n",
              "      <td>0.917943</td>\n",
              "      <td>0.981103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.025500</td>\n",
              "      <td>0.069776</td>\n",
              "      <td>0.916352</td>\n",
              "      <td>0.938405</td>\n",
              "      <td>0.927247</td>\n",
              "      <td>0.982884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3250\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to distilbert-finetuned-ner/checkpoint-1756\n",
            "Configuration saved in distilbert-finetuned-ner/checkpoint-1756/config.json\n",
            "Model weights saved in distilbert-finetuned-ner/checkpoint-1756/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-finetuned-ner/checkpoint-1756/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-finetuned-ner/checkpoint-1756/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3250\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to distilbert-finetuned-ner/checkpoint-3512\n",
            "Configuration saved in distilbert-finetuned-ner/checkpoint-3512/config.json\n",
            "Model weights saved in distilbert-finetuned-ner/checkpoint-3512/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-finetuned-ner/checkpoint-3512/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-finetuned-ner/checkpoint-3512/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3250\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to distilbert-finetuned-ner/checkpoint-5268\n",
            "Configuration saved in distilbert-finetuned-ner/checkpoint-5268/config.json\n",
            "Model weights saved in distilbert-finetuned-ner/checkpoint-5268/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-finetuned-ner/checkpoint-5268/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-finetuned-ner/checkpoint-5268/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 327.99\n",
            "Samples/second: 128.43\n",
            "GPU memory occupied: 2846 MB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_gpu_utilization()"
      ],
      "metadata": {
        "id": "mL1aX8YqjEYR",
        "outputId": "284cbd63-393a-474d-f461-8cc3d23cbfae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU memory occupied: 2846 MB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(trainer.train_dataset)"
      ],
      "metadata": {
        "id": "c3a0jvjCQELL",
        "outputId": "d8de8f4a-7648-485e-8968-e6127a600e41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('my_saved_model')"
      ],
      "metadata": {
        "id": "oAT4Qbrkf28w",
        "outputId": "03fb0a94-1740-41a7-c437-0b624fb758b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to my_saved_model\n",
            "Configuration saved in my_saved_model/config.json\n",
            "Model weights saved in my_saved_model/pytorch_model.bin\n",
            "tokenizer config file saved in my_saved_model/tokenizer_config.json\n",
            "Special tokens file saved in my_saved_model/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\n",
        "    \"token-classification\",\n",
        "    model='my_saved_model',\n",
        "    aggregation_strategy=\"none\",\n",
        "    ignore_labels=[\"\"],\n",
        "    device=0\n",
        ")"
      ],
      "metadata": {
        "id": "rZ3gBQzhf6tZ",
        "outputId": "e6263c05-c5b3-48f4-9143-cefe8971ad3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file my_saved_model/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"my_saved_model\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"B-PER\",\n",
            "    \"2\": \"I-PER\",\n",
            "    \"3\": \"B-ORG\",\n",
            "    \"4\": \"I-ORG\",\n",
            "    \"5\": \"B-LOC\",\n",
            "    \"6\": \"I-LOC\",\n",
            "    \"7\": \"B-MISC\",\n",
            "    \"8\": \"I-MISC\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"B-LOC\": 5,\n",
            "    \"B-MISC\": 7,\n",
            "    \"B-ORG\": 3,\n",
            "    \"B-PER\": 1,\n",
            "    \"I-LOC\": 6,\n",
            "    \"I-MISC\": 8,\n",
            "    \"I-ORG\": 4,\n",
            "    \"I-PER\": 2,\n",
            "    \"O\": 0\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading configuration file my_saved_model/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"my_saved_model\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"B-PER\",\n",
            "    \"2\": \"I-PER\",\n",
            "    \"3\": \"B-ORG\",\n",
            "    \"4\": \"I-ORG\",\n",
            "    \"5\": \"B-LOC\",\n",
            "    \"6\": \"I-LOC\",\n",
            "    \"7\": \"B-MISC\",\n",
            "    \"8\": \"I-MISC\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"B-LOC\": 5,\n",
            "    \"B-MISC\": 7,\n",
            "    \"B-ORG\": 3,\n",
            "    \"B-PER\": 1,\n",
            "    \"I-LOC\": 6,\n",
            "    \"I-MISC\": 8,\n",
            "    \"I-ORG\": 4,\n",
            "    \"I-PER\": 2,\n",
            "    \"O\": 0\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file my_saved_model/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertForTokenClassification.\n",
            "\n",
            "All the weights of DistilBertForTokenClassification were initialized from the model checkpoint at my_saved_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForTokenClassification for predictions without further training.\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"O excelentíssimo presidente Luis Silva Bueno visitou ontem a Universidade Federal de Manaus do estado do Amazonas, Brasil\"\n",
        "results = ner(s)"
      ],
      "metadata": {
        "id": "Hnu-No5mg8yt"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "xRKNXReHITP6",
        "outputId": "3e6642e9-5989-4498-90aa-849e2dc25551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'O',\n",
              "  'score': 0.90171427,\n",
              "  'index': 1,\n",
              "  'word': 'O',\n",
              "  'start': 0,\n",
              "  'end': 1},\n",
              " {'entity': 'O',\n",
              "  'score': 0.99105835,\n",
              "  'index': 2,\n",
              "  'word': 'ex',\n",
              "  'start': 2,\n",
              "  'end': 4},\n",
              " {'entity': 'O',\n",
              "  'score': 0.9698714,\n",
              "  'index': 3,\n",
              "  'word': '##cel',\n",
              "  'start': 4,\n",
              "  'end': 7},\n",
              " {'entity': 'O',\n",
              "  'score': 0.87647444,\n",
              "  'index': 4,\n",
              "  'word': '##ent',\n",
              "  'start': 7,\n",
              "  'end': 10},\n",
              " {'entity': 'O',\n",
              "  'score': 0.55733407,\n",
              "  'index': 5,\n",
              "  'word': '##ís',\n",
              "  'start': 10,\n",
              "  'end': 12},\n",
              " {'entity': 'O',\n",
              "  'score': 0.6009466,\n",
              "  'index': 6,\n",
              "  'word': '##si',\n",
              "  'start': 12,\n",
              "  'end': 14},\n",
              " {'entity': 'O',\n",
              "  'score': 0.5632206,\n",
              "  'index': 7,\n",
              "  'word': '##mo',\n",
              "  'start': 14,\n",
              "  'end': 16},\n",
              " {'entity': 'O',\n",
              "  'score': 0.9990558,\n",
              "  'index': 8,\n",
              "  'word': 'president',\n",
              "  'start': 17,\n",
              "  'end': 26},\n",
              " {'entity': 'O',\n",
              "  'score': 0.99827135,\n",
              "  'index': 9,\n",
              "  'word': '##e',\n",
              "  'start': 26,\n",
              "  'end': 27},\n",
              " {'entity': 'B-PER',\n",
              "  'score': 0.9983644,\n",
              "  'index': 10,\n",
              "  'word': 'Luis',\n",
              "  'start': 28,\n",
              "  'end': 32},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.9961175,\n",
              "  'index': 11,\n",
              "  'word': 'Silva',\n",
              "  'start': 33,\n",
              "  'end': 38},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.99201185,\n",
              "  'index': 12,\n",
              "  'word': 'B',\n",
              "  'start': 39,\n",
              "  'end': 40},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.9940969,\n",
              "  'index': 13,\n",
              "  'word': '##uen',\n",
              "  'start': 40,\n",
              "  'end': 43},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.99387544,\n",
              "  'index': 14,\n",
              "  'word': '##o',\n",
              "  'start': 43,\n",
              "  'end': 44},\n",
              " {'entity': 'O',\n",
              "  'score': 0.9992836,\n",
              "  'index': 15,\n",
              "  'word': 'visit',\n",
              "  'start': 45,\n",
              "  'end': 50},\n",
              " {'entity': 'O',\n",
              "  'score': 0.99352276,\n",
              "  'index': 16,\n",
              "  'word': '##ou',\n",
              "  'start': 50,\n",
              "  'end': 52},\n",
              " {'entity': 'O',\n",
              "  'score': 0.99926513,\n",
              "  'index': 17,\n",
              "  'word': 'on',\n",
              "  'start': 53,\n",
              "  'end': 55},\n",
              " {'entity': 'O',\n",
              "  'score': 0.9951923,\n",
              "  'index': 18,\n",
              "  'word': '##tem',\n",
              "  'start': 55,\n",
              "  'end': 58},\n",
              " {'entity': 'O',\n",
              "  'score': 0.9884338,\n",
              "  'index': 19,\n",
              "  'word': 'a',\n",
              "  'start': 59,\n",
              "  'end': 60},\n",
              " {'entity': 'B-ORG',\n",
              "  'score': 0.98215336,\n",
              "  'index': 20,\n",
              "  'word': 'Universidad',\n",
              "  'start': 61,\n",
              "  'end': 72},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.9977858,\n",
              "  'index': 21,\n",
              "  'word': '##e',\n",
              "  'start': 72,\n",
              "  'end': 73},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.99738854,\n",
              "  'index': 22,\n",
              "  'word': 'Federal',\n",
              "  'start': 74,\n",
              "  'end': 81},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.9975314,\n",
              "  'index': 23,\n",
              "  'word': 'de',\n",
              "  'start': 82,\n",
              "  'end': 84},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.9933664,\n",
              "  'index': 24,\n",
              "  'word': 'Man',\n",
              "  'start': 85,\n",
              "  'end': 88},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.99018294,\n",
              "  'index': 25,\n",
              "  'word': '##aus',\n",
              "  'start': 88,\n",
              "  'end': 91},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.82688373,\n",
              "  'index': 26,\n",
              "  'word': 'do',\n",
              "  'start': 92,\n",
              "  'end': 94},\n",
              " {'entity': 'O',\n",
              "  'score': 0.6319469,\n",
              "  'index': 27,\n",
              "  'word': 'est',\n",
              "  'start': 95,\n",
              "  'end': 98},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.57382745,\n",
              "  'index': 28,\n",
              "  'word': '##ado',\n",
              "  'start': 98,\n",
              "  'end': 101},\n",
              " {'entity': 'O',\n",
              "  'score': 0.6743975,\n",
              "  'index': 29,\n",
              "  'word': 'do',\n",
              "  'start': 102,\n",
              "  'end': 104},\n",
              " {'entity': 'B-LOC',\n",
              "  'score': 0.85141057,\n",
              "  'index': 30,\n",
              "  'word': 'Amazon',\n",
              "  'start': 105,\n",
              "  'end': 111},\n",
              " {'entity': 'I-LOC',\n",
              "  'score': 0.92806345,\n",
              "  'index': 31,\n",
              "  'word': '##as',\n",
              "  'start': 111,\n",
              "  'end': 113},\n",
              " {'entity': 'O',\n",
              "  'score': 0.99896634,\n",
              "  'index': 32,\n",
              "  'word': ',',\n",
              "  'start': 113,\n",
              "  'end': 114},\n",
              " {'entity': 'B-LOC',\n",
              "  'score': 0.99866533,\n",
              "  'index': 33,\n",
              "  'word': 'Brasil',\n",
              "  'start': 115,\n",
              "  'end': 121}]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(results)):\n",
        "    print(results[i])\n",
        "    #print(f\"the {i}-th result={results[i]['token_str']} has score {results[i]['score']}\")"
      ],
      "metadata": {
        "id": "HOmcOSd_2Oj-",
        "outputId": "bf8511d2-a709-4569-e0ff-57679533606c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'entity': 'O', 'score': 0.90171427, 'index': 1, 'word': 'O', 'start': 0, 'end': 1}\n",
            "{'entity': 'O', 'score': 0.99105835, 'index': 2, 'word': 'ex', 'start': 2, 'end': 4}\n",
            "{'entity': 'O', 'score': 0.9698714, 'index': 3, 'word': '##cel', 'start': 4, 'end': 7}\n",
            "{'entity': 'O', 'score': 0.87647444, 'index': 4, 'word': '##ent', 'start': 7, 'end': 10}\n",
            "{'entity': 'O', 'score': 0.55733407, 'index': 5, 'word': '##ís', 'start': 10, 'end': 12}\n",
            "{'entity': 'O', 'score': 0.6009466, 'index': 6, 'word': '##si', 'start': 12, 'end': 14}\n",
            "{'entity': 'O', 'score': 0.5632206, 'index': 7, 'word': '##mo', 'start': 14, 'end': 16}\n",
            "{'entity': 'O', 'score': 0.9990558, 'index': 8, 'word': 'president', 'start': 17, 'end': 26}\n",
            "{'entity': 'O', 'score': 0.99827135, 'index': 9, 'word': '##e', 'start': 26, 'end': 27}\n",
            "{'entity': 'B-PER', 'score': 0.9983644, 'index': 10, 'word': 'Luis', 'start': 28, 'end': 32}\n",
            "{'entity': 'I-PER', 'score': 0.9961175, 'index': 11, 'word': 'Silva', 'start': 33, 'end': 38}\n",
            "{'entity': 'I-PER', 'score': 0.99201185, 'index': 12, 'word': 'B', 'start': 39, 'end': 40}\n",
            "{'entity': 'I-PER', 'score': 0.9940969, 'index': 13, 'word': '##uen', 'start': 40, 'end': 43}\n",
            "{'entity': 'I-PER', 'score': 0.99387544, 'index': 14, 'word': '##o', 'start': 43, 'end': 44}\n",
            "{'entity': 'O', 'score': 0.9992836, 'index': 15, 'word': 'visit', 'start': 45, 'end': 50}\n",
            "{'entity': 'O', 'score': 0.99352276, 'index': 16, 'word': '##ou', 'start': 50, 'end': 52}\n",
            "{'entity': 'O', 'score': 0.99926513, 'index': 17, 'word': 'on', 'start': 53, 'end': 55}\n",
            "{'entity': 'O', 'score': 0.9951923, 'index': 18, 'word': '##tem', 'start': 55, 'end': 58}\n",
            "{'entity': 'O', 'score': 0.9884338, 'index': 19, 'word': 'a', 'start': 59, 'end': 60}\n",
            "{'entity': 'B-ORG', 'score': 0.98215336, 'index': 20, 'word': 'Universidad', 'start': 61, 'end': 72}\n",
            "{'entity': 'I-ORG', 'score': 0.9977858, 'index': 21, 'word': '##e', 'start': 72, 'end': 73}\n",
            "{'entity': 'I-ORG', 'score': 0.99738854, 'index': 22, 'word': 'Federal', 'start': 74, 'end': 81}\n",
            "{'entity': 'I-ORG', 'score': 0.9975314, 'index': 23, 'word': 'de', 'start': 82, 'end': 84}\n",
            "{'entity': 'I-ORG', 'score': 0.9933664, 'index': 24, 'word': 'Man', 'start': 85, 'end': 88}\n",
            "{'entity': 'I-ORG', 'score': 0.99018294, 'index': 25, 'word': '##aus', 'start': 88, 'end': 91}\n",
            "{'entity': 'I-ORG', 'score': 0.82688373, 'index': 26, 'word': 'do', 'start': 92, 'end': 94}\n",
            "{'entity': 'O', 'score': 0.6319469, 'index': 27, 'word': 'est', 'start': 95, 'end': 98}\n",
            "{'entity': 'I-ORG', 'score': 0.57382745, 'index': 28, 'word': '##ado', 'start': 98, 'end': 101}\n",
            "{'entity': 'O', 'score': 0.6743975, 'index': 29, 'word': 'do', 'start': 102, 'end': 104}\n",
            "{'entity': 'B-LOC', 'score': 0.85141057, 'index': 30, 'word': 'Amazon', 'start': 105, 'end': 111}\n",
            "{'entity': 'I-LOC', 'score': 0.92806345, 'index': 31, 'word': '##as', 'start': 111, 'end': 113}\n",
            "{'entity': 'O', 'score': 0.99896634, 'index': 32, 'word': ',', 'start': 113, 'end': 114}\n",
            "{'entity': 'B-LOC', 'score': 0.99866533, 'index': 33, 'word': 'Brasil', 'start': 115, 'end': 121}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test\n",
        "test_data = tokenizer(s)\n",
        "print(\"Tokenized Data:\", test_data)\n",
        "print(\"Word Tokens:\", data['train'][idx]['tokens'])\n",
        "print(\"Word IDs:\", test_data.word_ids())\n",
        "print(\"Sub-Word Tokens:\", test_data.tokens())"
      ],
      "metadata": {
        "id": "b0UA9OL-O8Uu",
        "outputId": "62390a12-ede0-42d0-ed1b-bdf8ca8ac4ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Data: {'input_ids': [101, 152, 4252, 18389, 3452, 16928, 5053, 3702, 2084, 1162, 6132, 11211, 139, 23404, 1186, 3143, 6094, 1113, 18408, 170, 17572, 1162, 3467, 1260, 2268, 25134, 1202, 12890, 9359, 1202, 9786, 2225, 117, 23381, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "Word Tokens: ['LONDON', '1996-08-22']\n",
            "Word IDs: [None, 0, 1, 1, 1, 1, 1, 1, 2, 2, 3, 4, 5, 5, 5, 6, 6, 7, 7, 8, 9, 9, 10, 11, 12, 12, 13, 14, 14, 15, 16, 16, 17, 18, None]\n",
            "Sub-Word Tokens: ['[CLS]', 'O', 'ex', '##cel', '##ent', '##ís', '##si', '##mo', 'president', '##e', 'Luis', 'Silva', 'B', '##uen', '##o', 'visit', '##ou', 'on', '##tem', 'a', 'Universidad', '##e', 'Federal', 'de', 'Man', '##aus', 'do', 'est', '##ado', 'do', 'Amazon', '##as', ',', 'Brasil', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat my_saved_model/config.json"
      ],
      "metadata": {
        "id": "2CmOLZhe030k",
        "outputId": "d4be5bcb-0493-44ef-fadf-4bdfaa8dcb75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"_name_or_path\": \"distilbert-base-cased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"B-PER\",\n",
            "    \"2\": \"I-PER\",\n",
            "    \"3\": \"B-ORG\",\n",
            "    \"4\": \"I-ORG\",\n",
            "    \"5\": \"B-LOC\",\n",
            "    \"6\": \"I-LOC\",\n",
            "    \"7\": \"B-MISC\",\n",
            "    \"8\": \"I-MISC\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"B-LOC\": 5,\n",
            "    \"B-MISC\": 7,\n",
            "    \"B-ORG\": 3,\n",
            "    \"B-PER\": 1,\n",
            "    \"I-LOC\": 6,\n",
            "    \"I-MISC\": 8,\n",
            "    \"I-ORG\": 4,\n",
            "    \"I-PER\": 2,\n",
            "    \"O\": 0\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lL5Sy05n-rnv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}